# SupportBot â€” Algorithm & Architecture (Full Technical Reference)

**Last Updated**: 2026-02-23  
**Status**: Current & Accurate (reflects production code)

---

## Table of Contents

1. [System Overview](#1-system-overview)
2. [Services & Components](#2-services--components)
3. [Data Stores](#3-data-stores)
4. [Live Message Pipeline](#4-live-message-pipeline)
5. [Case Extraction Pipeline (BUFFER_UPDATE)](#5-case-extraction-pipeline-buffer_update)
6. [Answer Pipeline (MAYBE_RESPOND)](#6-answer-pipeline-maybe_respond)
7. [Emoji Reaction & Case Confirmation](#7-emoji-reaction--case-confirmation)
8. [History Ingestion (signal-ingest)](#8-history-ingestion-signal-ingest)
9. [Answer Engine Context Layers (SCRAG / B3 / B1)](#9-answer-engine-context-layers-scrag--b3--b1)
10. [LLM Calls Reference](#10-llm-calls-reference)
11. [Worker Maintenance Tasks](#11-worker-maintenance-tasks)
12. [Case Lifecycle Summary](#12-case-lifecycle-summary)
13. [Configuration Parameters](#13-configuration-parameters)
14. [Error Handling Patterns](#14-error-handling-patterns)

---

## 1. System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         SIGNAL GROUP CHAT                                  â”‚
â”‚  Users send messages, images, emoji reactions to a Signal support group    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚ Messages / Reactions
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      signal-desktop (headless)                            â”‚
â”‚  - Runs Signal Desktop in headless mode with SQLite DB (SQLCipher)        â”‚
â”‚  - Exposes HTTP API: /group/messages, /group/send, /reactions, etc.       â”‚
â”‚  - Polls for new messages and reactions                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚ HTTP
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        signal-bot (FastAPI)                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Ingest Layer    â”‚  â”‚  Worker (2 queues)  â”‚  â”‚  HTTP API (web)      â”‚  â”‚
â”‚  â”‚                 â”‚  â”‚                    â”‚  â”‚                      â”‚  â”‚
â”‚  â”‚ ingest_message  â”‚  â”‚  BUFFER_UPDATE      â”‚  â”‚  /case/{id}          â”‚  â”‚
â”‚  â”‚ _handle_react.  â”‚  â”‚  MAYBE_RESPOND      â”‚  â”‚  /history/cases      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                     â”‚                                         â”‚
â”‚           â–¼                     â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  MySQL Database                                                     â”‚  â”‚
â”‚  â”‚  raw_messages Â· buffers Â· cases Â· reactions Â· jobs Â· admin_sessions â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                     â”‚                                         â”‚
â”‚           â–¼                     â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚  ChromaDB (SCRAG)â”‚  â”‚  Gemini API (LLM)       â”‚                        â”‚
â”‚  â”‚  Vector store of â”‚  â”‚  - gemini-2.0-flash      â”‚                        â”‚
â”‚  â”‚  solved cases    â”‚  â”‚  - gemini-embedding-001   â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²
         â”‚  HTTP POST /history/cases
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       signal-ingest                                       â”‚
â”‚  History ingestion service:                                               â”‚
â”‚  - Triggers QR-code linking of admin's Signal account                    â”‚
â”‚  - Reads 45-day chat history from signal-desktop                         â”‚
â”‚  - Extracts solved cases with LLM                                         â”‚
â”‚  - Posts cases to signal-bot                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²
         â”‚  Browser / signal-web
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      signal-web (Next.js)                                 â”‚
â”‚  Public web UI for viewing case details, chat history, emoji confirmationsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Services & Components

| Service | Technology | Role |
|---------|-----------|------|
| `signal-desktop` | Python FastAPI + SQLCipher | Reads/writes Signal Desktop SQLite DB; exposes HTTP API for messages and reactions |
| `signal-bot` | Python FastAPI | Core backend: ingest, worker queues, LLM orchestration, case DB, RAG |
| `signal-ingest` | Python | History import: QR-link admin account, bulk-extract cases from past messages |
| `signal-web` | Next.js (React) | Case viewer web app; displays case details, chat history, confirmation emoji |
| MySQL | MySQL 8 | Primary persistent store: messages, buffers, cases, jobs, sessions |
| ChromaDB | Chroma | Vector store for semantic search over solved cases (SCRAG layer) |
| Gemini API | Google | All LLM calls: gating, case extraction, embedding, answer synthesis |

### Key source files

```
signal-bot/app/
â”œâ”€â”€ main.py                  â† FastAPI app, signal listener, reaction handler
â”œâ”€â”€ ingestion.py             â† ingest_message(): store + enqueue jobs
â”œâ”€â”€ jobs/worker.py           â† BUFFER_UPDATE and MAYBE_RESPOND job handlers
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ ultimate_agent.py    â† UltimateAgent: gate â†’ search â†’ synthesize
â”‚   â””â”€â”€ case_search_agent.py â† CaseSearchAgent: SCRAG + B3 + B1 retrieval
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ client.py            â† LLMClient: all Gemini API calls
â”‚   â”œâ”€â”€ prompts.py           â† All system prompts (P_BLOCKS_SYSTEM, etc.)
â”‚   â””â”€â”€ schemas.py           â† Pydantic output schemas
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ queries_mysql.py     â† All SQL queries
â”‚   â””â”€â”€ schema_mysql.py      â† DB schema (create tables)
â””â”€â”€ rag/chroma.py            â† ChromaDB wrapper (SCRAG)

signal-ingest/ingest/main.py â† History ingestion pipeline
signal-desktop/app/
â”œâ”€â”€ db_reader.py             â† Reads Signal Desktop SQLite (SQLCipher)
â””â”€â”€ main.py                  â† FastAPI HTTP API over db_reader
```

---

## 3. Data Stores

### MySQL Tables

| Table | Purpose |
|-------|---------|
| `raw_messages` | Every ingested message: `message_id`, `group_id`, `ts`, `sender_hash`, `content_text` (with OCR'd image JSON), `image_paths`, `reply_to_id` |
| `buffers` | Per-group rolling message buffer (plain text, used for LLM case extraction) |
| `cases` | All cases: `case_id`, `group_id`, `status` (open/solved/archived), `problem_title`, `problem_summary`, `solution_summary`, `tags`, `evidence_ids`, `embedding`, `in_rag`, `closed_emoji` |
| `reactions` | Emoji reactions: `group_id`, `target_ts`, `target_author`, `sender_hash`, `emoji` |
| `jobs` | Worker job queue: `job_id`, `type` (BUFFER_UPDATE/MAYBE_RESPOND/HISTORY_LINK), `payload`, `status`, `attempts` |
| `admin_sessions` | Linked admin accounts: `admin_id` (phone), `group_id`, `lang` |
| `history_tokens` | One-time tokens for history import authorization |
| `group_docs` | Optional documentation URLs per group (for `/setdocs` command) |

### ChromaDB (SCRAG)

One collection, keyed by `case_id`. Each entry:
- **document**: structured text â€” `[SOLVED] <title>\nĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°: ...\nĞ Ñ–ÑˆĞµĞ½Ğ½Ñ: ...\ntags: ...`
- **embedding**: 768-dim vector from `gemini-embedding-001`
- **metadata**: `{group_id, status, evidence_ids?, evidence_image_paths?}`

SCRAG is the permanent semantic knowledge base. It only contains **solved** cases with a non-empty solution summary.

---

## 4. Live Message Pipeline

Every message from Signal Desktop flows through this path:

```
Signal Desktop polls its SQLite DB every few seconds
        â”‚
        â–¼
SignalDesktopAdapter.listen_forever()
  - Gets new group messages â†’ _handle_group_message(m)
  - Gets reactions          â†’ _handle_reaction(r)
  - Gets contact-removed    â†’ _handle_contact_removed(phone)
        â”‚
        â–¼ (group message)
ingest_message(settings, db, llm, message_id, group_id, sender, ts, text, image_paths)
        â”‚
        â”œâ”€ Image processing (if attachments):
        â”‚     for each image:
        â”‚       llm.image_to_text_json(image_bytes, context_text)
        â”‚         â†’ ImgExtract {observations: List[str], extracted_text: str}
        â”‚       append to content_text:
        â”‚         "\n\n[image]\n{json}"
        â”‚
        â”œâ”€ insert_raw_message(db, RawMessage{...})
        â”‚     â† idempotent; skips if message_id already exists
        â”‚
        â””â”€ enqueue_job(db, BUFFER_UPDATE, payload)
           enqueue_job(db, MAYBE_RESPOND, payload)
```

### Image Processing Details

Images attached to Signal messages are processed immediately at ingest time:
- Calls `llm.image_to_text_json(image_bytes, context_text=original_text)` using `P_IMG_SYSTEM` prompt
- Returns structured JSON: `{"observations": [...], "extracted_text": "..."}`
- This JSON is appended to `content_text` in `raw_messages` so all subsequent LLM calls see the OCR output
- Original image bytes are stored on disk at `settings.signal_bot_storage` path

---

## 5. Case Extraction Pipeline (BUFFER_UPDATE)

Triggered for every new message. Purpose: maintain the rolling buffer (B2) and extract new cases.

```
BUFFER_UPDATE job consumed by worker_loop_forever()
        â”‚
        â–¼
_handle_buffer_update(deps, payload)
        â”‚
        â”œâ”€ Load message from raw_messages
        â”œâ”€ Check positive reactions on this message (from reactions table)
        â”œâ”€ Mark as [BOT] if sender_hash == bot_sender_hash
        â”œâ”€ Append formatted buffer line:
        â”‚     "{sender_hash}[BOT?] ts={ts} msg_id={msg_id} reactions=N\n{content_text}\n\n"
        â”‚
        â”œâ”€ Trim buffer:
        â”‚     - Remove messages older than buffer_max_age_hours
        â”‚     - Remove oldest messages if > buffer_max_messages
        â”‚
        â”œâ”€ Parse buffer into indexed message blocks (BufferMessageBlock)
        â”‚
        â”œâ”€ Filter out [BOT] blocks for extraction input
        â”‚     (bot messages kept in buffer for context but never become cases)
        â”‚
        â”œâ”€â”€â”€ PHASE 1: Extract new case spans â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        â”‚
        â”‚   llm.extract_case_from_buffer(numbered_buffer)
        â”‚     [P_EXTRACT_SYSTEM prompt + gemini-2.0-flash]
        â”‚     â†’ ExtractResult {cases: [{start_idx, end_idx}]}
        â”‚
        â”‚   for each span (start_idx â†’ end_idx):
        â”‚     case_block_text = join messages in span
        â”‚
        â”‚     llm.make_case(case_block_text)
        â”‚       [P_CASE_SYSTEM prompt + gemini-2.0-flash]
        â”‚       â†’ CaseResult {keep, status, problem_title, problem_summary,
        â”‚                      solution_summary, tags}
        â”‚
        â”‚     if not case.keep â†’ skip
        â”‚
        â”‚     Semantic dedup:
        â”‚       embed_text = f"{problem_title}\n{problem_summary}"
        â”‚       embedding = llm.embed(embed_text)
        â”‚       similar_id = find_similar_case(db, group_id, embedding)
        â”‚
        â”‚       if similar_id:
        â”‚         merge_case(db, target=similar_id, ...) â†’ update existing
        â”‚       else:
        â”‚         insert_case(db, new case_id, status=open/solved, ...)
        â”‚       store_case_embedding(db, case_id, embedding)
        â”‚
        â”‚     if status == "solved" AND solution not empty:
        â”‚       Build doc_text:
        â”‚         "[SOLVED] {title}\nĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°: {problem}\nĞ Ñ–ÑˆĞµĞ½Ğ½Ñ: {solution}\ntags: ..."
        â”‚       rag_embedding = llm.embed(doc_text)
        â”‚       rag.upsert_case(case_id, doc_text, rag_embedding, metadata)
        â”‚       mark_case_in_rag(db, case_id)
        â”‚       accepted_ranges.append(span) â† will be removed from buffer
        â”‚     else:
        â”‚       store as B1 open case, keep messages in buffer
        â”‚
        â”œâ”€â”€â”€ PHASE 2: Dynamic B1 Resolution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        â”‚
        â”‚   open_cases = get_open_cases_for_group(db, group_id)  â† B1
        â”‚
        â”‚   for each b1_case:
        â”‚     resolution = llm.check_case_resolved(
        â”‚         case_title, case_problem, buffer_text=full_buf)
        â”‚       [P_RESOLUTION_SYSTEM prompt + gemini-2.0-flash]
        â”‚       â†’ ResolutionResult {resolved: bool, solution_summary: str}
        â”‚
        â”‚     if resolved AND solution not empty:
        â”‚       Semantic dedup: check for existing solved case
        â”‚         if exists â†’ merge + archive b1_case
        â”‚         else      â†’ update_case_to_solved(db, case_id, solution)
        â”‚       upsert to SCRAG (mark_case_in_rag)
        â”‚
        â””â”€â”€â”€ Update buffer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

            Remove message spans that became solved cases (accepted_ranges)
            set_buffer(db, group_id, buffer_new)
```

### Buffer Line Format

```
{sender_hash}[BOT] ts={timestamp_ms} msg_id={uuid} reply_to={uuid} reactions=N
{content_text}

```

- `[BOT]` tag: only for messages from the bot's own phone number
- `reactions=N`: count of positive emoji reactions from the `reactions` table
- `reply_to=`: quoted message ID (from Signal's quote feature)
- `msg_id=`: used by LLM to output `evidence_ids` for case linking

---

## 6. Answer Pipeline (MAYBE_RESPOND)

Triggered for every new message. Purpose: decide if and how to respond.

```
MAYBE_RESPOND job consumed by worker_loop_forever()
        â”‚
        â–¼
_handle_maybe_respond(deps, payload)
        â”‚
        â”œâ”€ Load message from raw_messages
        â”œâ”€ Skip if content_text is empty (system notification)
        â”‚
        â”œâ”€ Check group has active linked admins
        â”‚     get_group_admins(db, group_id) â†’ admin phone numbers
        â”‚     for each admin â†’ get_admin_session(db, admin_id)
        â”‚     if no active sessions â†’ STOP (group not configured)
        â”‚
        â”œâ”€ Handle /setdocs command (admin-only)
        â”‚     upsert_group_docs(db, group_id, urls)
        â”‚
        â”œâ”€â”€â”€ GATE: decide_consider() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        â”‚
        â”‚   context_text = last 9 messages (excluding current)
        â”‚   gate_images  = first 2 attached images (if present)
        â”‚
        â”‚   gate = llm.decide_consider(
        â”‚       message=content_text,
        â”‚       context=context_text,
        â”‚       images=gate_images)
        â”‚     [P_DECISION_SYSTEM prompt + gemini-2.0-flash (fast)]
        â”‚     â†’ DecisionResult {consider: bool, tag: str}
        â”‚
        â”‚   Tags: new_question | ongoing_discussion | statement | noise
        â”‚
        â”‚   if not gate.consider AND not force:
        â”‚     STOP (silent)
        â”‚
        â”œâ”€â”€â”€ ULTIMATE AGENT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        â”‚
        â”‚   answer = UltimateAgent.answer(
        â”‚       question=content_text, group_id, db, lang)
        â”‚
        â”‚   â”Œâ”€ CaseSearchAgent.answer() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   â”‚  1. SCRAG: embed query â†’ cosine search ChromaDB (top 3)     â”‚
        â”‚   â”‚  2. B3: get_recent_solved_cases(db, group_id, since_ts)     â”‚
        â”‚   â”‚         (solved cases with evidence still in B2 window)     â”‚
        â”‚   â”‚  3. B1: get_open_cases_for_group(db, group_id)              â”‚
        â”‚   â”‚                                                              â”‚
        â”‚   â”‚  Priority:                                                   â”‚
        â”‚   â”‚    SCRAG or B3 results â†’ return formatted solved context     â”‚
        â”‚   â”‚    Only B1 results    â†’ return "B1_ONLY:<context>"          â”‚
        â”‚   â”‚    Nothing            â†’ return "No relevant cases found."    â”‚
        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚   Synthesizer (gemini-2.0-flash) builds final answer:
        â”‚
        â”‚   if "No relevant cases found." â†’ answer = "[[TAG_ADMIN]]"
        â”‚
        â”‚   if "B1_ONLY:...":
        â”‚     Prompt: "state the issue is tracked + include case link + [[TAG_ADMIN]]"
        â”‚     â†’ 1-sentence response mentioning open case + admin tag
        â”‚
        â”‚   if solved cases found:
        â”‚     Prompt: "State the ACTUAL solution in 1-2 sentences. Add case link."
        â”‚             "If retrieved cases don't address question â†’ [[TAG_ADMIN]]"
        â”‚             "If user must provide something â†’ add [[TAG_ADMIN]] + link"
        â”‚     â†’ direct answer + case link
        â”‚
        â”œâ”€â”€â”€ SEND â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        â”‚
        â”‚   [[TAG_ADMIN]] â†’ replace with @mention of active admins
        â”‚
        â”‚   signal.send_group_text(
        â”‚       group_id=group_id,
        â”‚       text=answer,
        â”‚       quote_timestamp=original_ts,   â† bot replies quoting the user
        â”‚       quote_author=sender,
        â”‚       quote_message=original_text,
        â”‚       mention_recipients=admin_phones)
        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### Gate Prompt (P_DECISION_SYSTEM)

The gate model decides `consider=true/false` and classifies the message:

| Tag | Meaning | consider |
|-----|---------|----------|
| `new_question` | New support question, no related context | **true** |
| `ongoing_discussion` | Continues an active thread in context | **true** |
| `statement` | Summary / conclusion / "I solved it" without asking for help | **false** |
| `noise` | Greeting, "ok", emoji-only, off-topic | **false** |

Key rules:
- `consider=true` for technical problem descriptions (even if phrased as statements) â€” these are captured by BUFFER_UPDATE, not MAYBE_RESPOND
- `consider=false` for summaries that start with "ĞŸÑ–Ğ´ÑÑƒĞ¼Ğ¾Ğ²ÑƒÑÑ‡Ğ¸", "Ğ ĞµĞ·ÑĞ¼ÑƒÑÑ‡Ğ¸" etc.
- Bot mention (`force=true`) bypasses the gate

---

## 7. Emoji Reaction & Case Confirmation

Emoji reactions are a primary signal for confirming a case was solved.

```
Signal Desktop receives emoji reaction
        â”‚
        â–¼
_handle_reaction(r: InboundReaction)
        â”‚
        â”œâ”€ Hash sender: sender_h = hash_sender(r.sender)
        â”‚
        â”œâ”€ if r.is_remove:
        â”‚     delete_reaction(db, group_id, target_ts, sender_h, emoji)
        â”‚
        â””â”€ else:
              upsert_reaction(db, group_id, target_ts, target_author, sender_h, emoji)
              log "Reaction added"
              
              if r.emoji in POSITIVE_EMOJI:
                n = confirm_cases_by_evidence_ts(
                    db, group_id=r.group_id, target_ts=r.target_ts, emoji=r.emoji)
                
                if n > 0:
                  log "Case confirmation via emoji {emoji} on ts={ts}: {n} cases confirmed"
```

### POSITIVE_EMOJI Set

Defined in `app/db/__init__.py` (MySQL module). Includes thumbs up, heart, checkmark, and other approval emoji variants across Unicode code points.

### confirm_cases_by_evidence_ts()

SQL logic: find all `cases` where `evidence_ids` JSON array contains any message with timestamp `target_ts` in `raw_messages`, then:
- Update `status = 'solved'`
- Set `closed_emoji = r.emoji` (the actual emoji used, e.g. "ğŸ«¡", "+", "ğŸ‘")

This is also triggered from history ingestion when `reactions=N` is present in the chunk.

### closed_emoji Display (signal-web)

The `closed_emoji` field is stored in the `cases` table and displayed in the case page chat history:

```html
{data.closed_emoji && data.status === 'solved' && (
  <div className="emoji-confirmation">
    <span className="emoji-bubble">{data.closed_emoji}</span>
    Ğ£Ñ‡Ğ°ÑĞ½Ğ¸Ğº Ğ¿Ñ–Ğ´Ñ‚Ğ²ĞµÑ€Ğ´Ğ¸Ğ² Ğ²Ğ¸Ñ€Ñ–ÑˆĞµĞ½Ğ½Ñ Ñ€ĞµĞ°ĞºÑ†Ñ–Ñ”Ñ
  </div>
)}
```

This appears inside the chat history section (not the page header), showing the actual emoji the participant used.

---

## 8. History Ingestion (signal-ingest)

Used to backfill the knowledge base from past Signal chat history.

```
Admin initiates history import (via signal-web or API)
        â”‚
        â–¼
signal-bot: POST /history/link-token
  â†’ creates one-time token + HISTORY_LINK job
  â†’ sends DM to admin with QR link

HISTORY_LINK job picked up by worker:
  â†’ POST signal-ingest/jobs   {admin_id, group_id, token, lang}
  â†’ signal-ingest starts job

signal-ingest job flow:
        â”‚
        â”œâ”€ 1. Reset Signal Desktop (clear previous account)
        â”‚     POST signal-desktop/reset
        â”‚
        â”œâ”€ 2. Request new QR code
        â”‚     POST signal-desktop/link-account
        â”‚     â†’ returns QR code as base64 PNG
        â”‚
        â”œâ”€ 3. Send QR image to admin via signal-bot
        â”‚     POST signal-bot/history/qr-ready  {token, qr_base64}
        â”‚     â†’ signal-bot sends DM with QR to admin
        â”‚
        â”œâ”€ 4. Wait for admin to scan QR (links their account to signal-desktop)
        â”‚     Poll signal-desktop/status until linked (timeout: 5 min)
        â”‚
        â”œâ”€ 5. Fetch historical messages from signal-desktop
        â”‚     GET signal-desktop/group/{group_id}/messages
        â”‚     â†’ returns list of SignalMessage {ts, sender, text, reactions, reaction_emoji, ...}
        â”‚
        â”œâ”€ 6. Chunk messages and extract cases with LLM
        â”‚
        â”‚   _chunk_messages(messages, bot_e164):
        â”‚     - Skip bot messages (_is_bot_message: checks sender == bot_e164
        â”‚                          or "supportbot.info/case/" in text)
        â”‚     - Format each message header:
        â”‚         "{sender_hash} ts={ts} msg_id={msg_id}
        â”‚          reactions={N} reaction_emoji={emoji}"
        â”‚     - Split into overlapping chunks of ~150 messages
        â”‚
        â”‚   For each chunk:
        â”‚     LLM (P_BLOCKS_SYSTEM prompt) â†’ {cases: [{case_block: str}]}
        â”‚
        â”‚     P_BLOCKS_SYSTEM resolution signals:
        â”‚       STRONG: reactions=N (N>0) on a technical answer
        â”‚       MEDIUM: text confirmation ("Ğ´ÑĞºÑƒÑ", "Ğ¿Ñ€Ğ°Ñ†ÑÑ”", "ok", etc.)
        â”‚       WEAK:   conversation ends after technical answer
        â”‚       NOTE:   "thread ends" is intentionally kept as a weak signal;
        â”‚               bot replies are filtered out before LLM sees the chunk
        â”‚
        â”œâ”€ 7. Post extracted cases to signal-bot
        â”‚     POST signal-bot/history/cases
        â”‚       {token, cases: [{case_block, reaction_emoji?}]}
        â”‚
        â”‚     signal-bot _process_history_cases_bg():
        â”‚       for each case_block:
        â”‚         1. Parse evidence_ids from msg_id= headers
        â”‚         2. llm.make_case(case_block) â†’ CaseResult
        â”‚         3. Semantic dedup: find_similar_case() â†’ merge or insert
        â”‚         4. If emoji_confirmed (reactions=N in block):
        â”‚              extract reaction_emoji from "reaction_emoji=X" in block
        â”‚              UPDATE cases SET closed_emoji=X WHERE case_id=...
        â”‚         5. If solved: upsert to SCRAG
        â”‚
        â””â”€ 8. Reset Signal Desktop again (remove admin's account)
              POST signal-desktop/reset
              â†’ Privacy: admin's account is unlinked immediately after import
```

### History Case Extraction Prompt (P_BLOCKS_SYSTEM)

```
Analyze chunk of support chat history â†’ extract FULLY RESOLVED cases.

Message format: sender_hash ts=TIMESTAMP msg_id=MESSAGE_ID\nmessage text

Resolution signals (strongest â†’ weakest):
  1. reactions=N (N>0) on technical answer   â† STRONG, treat as confirmed
  2. Text confirmation after technical answer
     ("Ğ´ÑĞºÑƒÑ", "Ğ¿Ñ€Ğ°Ñ†ÑÑ”", "ok", "working", "thanks", etc.)
  3. Thread ends after technical answer      â† WEAK signal

Rules:
  - Extract ONLY solved cases (problem + confirmed solution)
  - Do NOT extract open/unresolved, greetings, off-topic
  - Preserve original message headers verbatim (needed for evidence_ids)
  - Bot messages are pre-filtered; never appear in the chunk input
  - Return {"cases": []} if no solved cases found
```

---

## 9. Answer Engine Context Layers (SCRAG / B3 / B1)

When answering a user question, the bot queries three context layers:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SCRAG â€” Solved Cases RAG (ChromaDB, permanent)                 â”‚
â”‚  â”œâ”€ Source: solved cases with non-empty solution summary        â”‚
â”‚  â”œâ”€ Indexed: immediately when a case is marked solved           â”‚
â”‚  â”œâ”€ Search: cosine similarity (gemini-embedding-001, 768-dim)   â”‚
â”‚  â”œâ”€ Filter: by group_id (each group has its own knowledge base) â”‚
â”‚  â””â”€ Top-K: 3 results returned                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  B3 â€” Recently Solved Buffer (MySQL query)                      â”‚
â”‚  â”œâ”€ Source: solved cases whose evidence_ts falls in B2 window   â”‚
â”‚  â”œâ”€ Query: get_recent_solved_cases(db, group_id, since_ts)      â”‚
â”‚  â””â”€ Purpose: catches cases solved in the last few days          â”‚
â”‚     before embedding had time to matter / before full SCRAG syncâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  B1 â€” Open Cases (MySQL query)                                  â”‚
â”‚  â”œâ”€ Source: cases WHERE status='open' AND group_id=?            â”‚
â”‚  â”œâ”€ Expiry: auto-deleted after 7 days (hourly B1 expiry job)    â”‚
â”‚  â””â”€ Use: tell user the issue is tracked, tag admin              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  B2 â€” Rolling Message Buffer (MySQL buffers table)              â”‚
â”‚  â”œâ”€ Content: all recent group messages as formatted text        â”‚
â”‚  â”œâ”€ Age limit: buffer_max_age_hours (configurable)              â”‚
â”‚  â”œâ”€ Size limit: buffer_max_messages (configurable)              â”‚
â”‚  â””â”€ Use: case extraction input (BUFFER_UPDATE) and B1 check     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Response Decision Tree

```
CaseSearchAgent.answer(question, group_id, db)
        â”‚
        â”œâ”€ SCRAG search (top 3) + B3 lookup
        â”‚
        â”œâ”€ Any solved results (SCRAG or B3)?
        â”‚     YES â†’ format context: problem + solution + case link
        â”‚           â†’ UltimateAgent synthesizer generates direct answer
        â”‚
        â”œâ”€ No solved results. Any B1 (open) cases?
        â”‚     YES â†’ format: "B1_ONLY:{open case context}"
        â”‚           â†’ synthesizer generates 1 sentence: "being tracked" + link + [[TAG_ADMIN]]
        â”‚
        â””â”€ Nothing at all â†’ "No relevant cases found."
              â†’ UltimateAgent returns "[[TAG_ADMIN]]"
              â†’ Worker replaces with @mention of active group admins
```

---

## 10. LLM Calls Reference

All calls use Gemini API via OpenAI-compatible endpoint. Models:

| Call | Function | Model | Purpose | Output Schema |
|------|----------|-------|---------|---------------|
| Image OCR | `llm.image_to_text_json()` | gemini-2.0-flash | Extract text & observations from image | `ImgExtract {observations, extracted_text}` |
| Gate | `llm.decide_consider()` | gemini-2.0-flash | Filter noise / classify message | `DecisionResult {consider, tag}` |
| Case extract | `llm.extract_case_from_buffer()` | gemini-2.0-flash | Find case spans in numbered buffer | `ExtractResult {cases: [{start_idx, end_idx}]}` |
| Case structure | `llm.make_case()` | gemini-2.0-flash | Structure a case block into fields | `CaseResult {keep, status, problem_title, problem_summary, solution_summary, tags}` |
| B1 resolution | `llm.check_case_resolved()` | gemini-2.0-flash | Check if open case resolved by new buffer | `ResolutionResult {resolved, solution_summary}` |
| Embed | `llm.embed()` | gemini-embedding-001 | 768-dim vector for dedup + SCRAG search | `List[float]` |
| Synthesize | `synthesizer.generate_content()` | gemini-2.0-flash | Final user-facing answer | Free text |
| History extract | P_BLOCKS_SYSTEM prompt | gemini-2.0-flash (via OpenAI client) | Extract solved cases from history chunk | `{cases: [{case_block: str}]}` |

### Embedding & Deduplication

Every case is embedded twice:
1. **Dedup embed**: `"{problem_title}\n{problem_summary}"` â€” used by `find_similar_case()` to prevent duplicate cases for the same problem
2. **SCRAG embed**: full `doc_text` (`[SOLVED] title\nĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°: ...\nĞ Ñ–ÑˆĞµĞ½Ğ½Ñ: ...\ntags: ...`) â€” used for semantic search at answer time

`find_similar_case()` uses a cosine similarity threshold (configurable) to decide if two cases are "the same problem". If a match is found, `merge_case()` updates the existing case rather than creating a new one.

---

## 11. Worker Maintenance Tasks

The worker loop runs two periodic maintenance tasks:

### B1 Expiry (hourly)
```python
expire_old_open_cases(db, max_age_days=7)
```
Open cases older than 7 days are deleted (the problem was never resolved or is stale).

### SCRAG Sync (hourly)
```python
_run_sync_rag(deps)
```
Compares ChromaDB entries against MySQL active case IDs. Removes stale ChromaDB entries whose MySQL case no longer exists (e.g. was archived or deleted). This is the authoritative reconciliation â€” keeps SCRAG consistent without per-query MySQL lookups.

---

## 12. Case Lifecycle Summary

```
MESSAGE ARRIVES
       â”‚
       â–¼
raw_messages: inserted (idempotent)
       â”‚
       â”œâ”€â”€ BUFFER_UPDATE: added to B2 buffer
       â”‚         â”‚
       â”‚         â”œâ”€â”€ LLM: extract_case_from_buffer()
       â”‚         â”‚         â”‚
       â”‚         â”‚         â”œâ”€â”€ make_case() â†’ status=open  â†’ B1 (cases table, in_rag=0)
       â”‚         â”‚         â”‚
       â”‚         â”‚         â””â”€â”€ make_case() â†’ status=solved â†’ SCRAG + B3 + remove from B2
       â”‚         â”‚
       â”‚         â””â”€â”€ For each B1 case: check_case_resolved()
       â”‚                   â”‚
       â”‚                   â””â”€â”€ resolved=true â†’ promote to solved â†’ SCRAG + B3
       â”‚
       â””â”€â”€ MAYBE_RESPOND: gate â†’ search (SCRAG+B3+B1) â†’ synthesize â†’ send

EMOJI REACTION
       â”‚
       â””â”€â”€ upsert_reaction â†’ confirm_cases_by_evidence_ts()
                 â†’ UPDATE cases SET status=solved, closed_emoji=emoji

HISTORY IMPORT
       â”‚
       â””â”€â”€ signal-ingest: LLM extracts from history chunks
                 â†’ POST /history/cases
                 â†’ make_case() â†’ insert/merge â†’ SCRAG (if solved)
                 â†’ closed_emoji set from reaction_emoji in chunk headers

CASE VIEWED
       â”‚
       â””â”€â”€ GET /api/case/{id} â†’ MySQL â†’ signal-web renders:
                 - problem title / summary
                 - solution summary
                 - full chat history (with timestamps)
                 - closed_emoji banner (in chat history)
```

---

## 13. Configuration Parameters

Key settings from `settings` (loaded from environment / `.env`):

| Setting | Default | Description |
|---------|---------|-------------|
| `buffer_max_age_hours` | 72 | B2 buffer: drop messages older than N hours |
| `buffer_max_messages` | 200 | B2 buffer: maximum message count |
| `worker_poll_seconds` | 1 | Job queue poll interval |
| `signal_bot_e164` | â€” | Bot's own phone number (for bot message detection) |
| `signal_bot_storage` | â€” | Path to Signal storage (images) |
| `signal_desktop_url` | â€” | signal-desktop HTTP API base URL |
| `use_signal_desktop` | false | Use Signal Desktop adapter vs signal-cli |
| `public_url` | â€” | Base URL for case links (e.g. `https://supportbot.info`) |
| `bot_mention_strings` | â€” | List of strings that trigger forced response |
| `max_image_size_bytes` | â€” | Skip images larger than this |
| `openai_api_key` | â€” | Google API key (used with OpenAI-compat endpoint) |

---

## 14. Error Handling Patterns

### Idempotency
- `insert_raw_message`: skips duplicate `message_id` (INSERT IGNORE)
- `upsert_case`: on conflict, updates existing case
- `rag.upsert_case`: Chroma upsert replaces existing entry

### Worker Retries
- Failed jobs are retried up to 3 times (`fail_job` increments `attempts`)
- After 3 failures, job is permanently marked failed

### Signal Adapter Fallbacks
- Signal Desktop not available at boot â†’ listener started lazily on first health check
- `send_direct_text` returns `False` â†’ triggers contact-removed cleanup (deletes admin session, unlinks groups)

### LLM Failures
- `_json_call` retries once on parse failure
- Gate failure: logs warning, proceeds without filter (better to respond than miss a question)
- Synthesizer failure: falls back to `"[[TAG_ADMIN]]"`
- History extract failure: logs, continues to next chunk

### Buffer Out-of-Range Spans
- If LLM returns `start_idx < 0` or `end_idx >= n_blocks` â†’ reject entire extract result for safety

### Periodic SCRAG Sync
- Handles partial failures in Chroma upsert/delete by reconciling hourly rather than per-operation

---

## Appendix: Key Data Flow Diagram

```
Signal Group Chat
        â”‚ message + reaction
        â–¼
signal-desktop (SQLCipher DB reader)
        â”‚ HTTP API
        â–¼
signal-bot ingest_message()
        â”‚
        â”œâ”€â”€ raw_messages (MySQL) â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ history import (signal-ingest)
        â”‚
        â”œâ”€â”€ BUFFER_UPDATE job
        â”‚         â”‚
        â”‚         â”œâ”€â”€ buffers (MySQL) â† B2
        â”‚         â”‚
        â”‚         â”œâ”€â”€ extract_case_from_buffer (LLM) â†’ spans
        â”‚         â”‚         â”‚
        â”‚         â”‚         â””â”€â”€ make_case (LLM) â†’ CaseResult
        â”‚         â”‚                   â”‚
        â”‚         â”‚                   â”œâ”€â”€ B1: cases (MySQL, status=open, in_rag=0)
        â”‚         â”‚                   â”‚
        â”‚         â”‚                   â””â”€â”€ SCRAG: cases (MySQL, in_rag=1)
        â”‚         â”‚                              + ChromaDB (vector index)
        â”‚         â”‚
        â”‚         â””â”€â”€ check_case_resolved (LLM) â†’ B1â†’solvedâ†’SCRAG
        â”‚
        â””â”€â”€ MAYBE_RESPOND job
                  â”‚
                  â”œâ”€â”€ decide_consider (LLM gate)
                  â”‚
                  â”œâ”€â”€ CaseSearchAgent
                  â”‚         â”œâ”€â”€ SCRAG: ChromaDB cosine search
                  â”‚         â”œâ”€â”€ B3: recent solved (MySQL)
                  â”‚         â””â”€â”€ B1: open cases (MySQL)
                  â”‚
                  â””â”€â”€ UltimateAgent synthesizer (Gemini)
                            â””â”€â”€ signal.send_group_text()
```
